{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from data_classes.IMDBLightningDataModule import IMDBLightningDataModule\r\n",
    "from models.ClassifierSystem import LightningClassifier\r\n",
    "from data_classes.pretrained_embeddings import get_pretrained_embeddings\r\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\r\n",
    "from pytorch_lightning import Trainer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "vocab, vectors = get_pretrained_embeddings()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "imdb_data = IMDBLightningDataModule(vocab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "classifier = LightningClassifier(vocab=vocab, vectors=vectors, embedding_size=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "logger = TensorBoardLogger('exp_logs', name='lstm')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "trainer = Trainer(max_epochs=10, gpus=1, auto_select_gpus=True, auto_scale_batch_size=False, auto_lr_find=True, logger=[logger])\r\n",
    "# , track_grad_norm=2, accumulate_grad_batches=8"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "trainer.test(classifier, imdb_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\franc\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing:   0%|          | 3/782 [00:00<00:32, 24.26it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\franc\\Documents\\inge_master_2\\web_and_text_analysis\\sentiment_analysis\\src\\data_classes\\IMDB.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return text_pipeline(self.data[idx][1]), torch.tensor(labels, dtype=torch.long)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing: 100%|██████████| 782/782 [00:46<00:00, 16.41it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test Acc': 0.5122399926185608, 'Test Loss': 0.6921125650405884}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 782/782 [00:46<00:00, 16.89it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:423: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'Test Loss': 0.6921125650405884, 'Test Acc': 0.5122399926185608}]"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "trainer.tune(classifier, imdb_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | LSTM             | 3.2 M \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "161 K     Trainable params\n",
      "3.0 M     Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.644    Total estimated model params size (MB)\n",
      "C:\\Users\\franc\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\franc\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint file at c:\\Users\\franc\\Documents\\inge_master_2\\web_and_text_analysis\\sentiment_analysis\\src\\lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at c:\\Users\\franc\\Documents\\inge_master_2\\web_and_text_analysis\\sentiment_analysis\\src\\lr_find_temp_model.ckpt\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:12<00:00,  8.12it/s]\n",
      "Learning rate set to 0.002754228703338169\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'lr_find': <pytorch_lightning.tuner.lr_finder._LRFinder at 0x1a76663f640>}"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "classifier.batch_size"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "classifier.learning_rate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.002754228703338169"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "trainer.fit(classifier, imdb_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | LSTM             | 3.2 M \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "161 K     Trainable params\n",
      "3.0 M     Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.644    Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9: 100%|██████████| 783/783 [01:32<00:00,  7.42it/s, loss=0.0609, v_num=5]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "trainer.test(classifier, imdb_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing: 100%|██████████| 782/782 [00:49<00:00, 14.91it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test Acc': 0.8784000277519226, 'Test Loss': 0.4879884421825409}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 782/782 [00:49<00:00, 15.82it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'Test Loss': 0.4879884421825409, 'Test Acc': 0.8784000277519226}]"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('deep_learning': conda)"
  },
  "interpreter": {
   "hash": "cfa97515b48ec924051b6584906c775d898061829fcbf4ab570c29d743c4fef7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}